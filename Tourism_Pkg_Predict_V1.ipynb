{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvni6PzWr16xVdYRj14tj3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sudu2025/TourPkg_Prediction/blob/main/Tourism_Pkg_Predict_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement\n",
        "\n",
        "**Business Context**\n",
        "\n",
        "\"Visit with Us,\" a leading travel company, is revolutionizing the tourism industry by leveraging data-driven strategies to optimize operations and customer engagement. While introducing a new package offering, such as the Wellness Tourism Package, the company faces challenges in targeting the right customers efficiently. The manual approach to identifying potential customers is inconsistent, time-consuming, and prone to errors, leading to missed opportunities and suboptimal campaign performance.\n",
        "\n",
        "To address these issues, the company aims to implement a scalable and automated system that integrates customer data, predicts potential buyers, and enhances decision-making for marketing strategies. By utilizing an MLOps pipeline, the company seeks to achieve seamless integration of data preprocessing, model development, deployment, and CI/CD practices for continuous improvement. This system will ensure efficient targeting of customers, timely updates to the predictive model, and adaptation to evolving customer behaviors, ultimately driving growth and customer satisfaction.\n",
        "\n",
        "**Objective**\n",
        "\n",
        "As an MLOps Engineer at \"Visit with Us,\" your responsibility is to **design and deploy an MLOps pipeline on GitHub to automate the end-to-end workflow for predicting customer purchases**. The primary objective is to build a model that predicts whether a customer will purchase the newly introduced Wellness Tourism Package before contacting them. The pipeline will include data cleaning, preprocessing, transformation, model building, training, evaluation, and deployment, ensuring consistent performance and scalability. By leveraging GitHub Actions for CI/CD integration, the system will enable automated updates, streamline model deployment, and improve operational efficiency. This robust predictive solution will empower policymakers to make data-driven decisions, enhance marketing strategies, and effectively target potential customers, thereby driving customer acquisition and business growth.\n",
        "\n",
        "**Data Description**\n",
        "\n",
        "The dataset contains customer and interaction data that serve as key attributes for predicting the likelihood of purchasing the Wellness Tourism Package. The detailed attributes are:\n",
        "\n",
        "\n",
        "**Customer Details**\n",
        "\n",
        "**CustomerID:** Unique identifier for each customer.\n",
        "\n",
        "**ProdTaken:** Target variable indicating whether the customer has purchased a package (0: No, 1: Yes).\n",
        "\n",
        "**Age:** Age of the customer.\n",
        "\n",
        "**TypeofContact:** The method by which the customer was contacted (Company Invited or Self Inquiry).\n",
        "\n",
        "**CityTier:** The city category based on development, population, and living standards (Tier 1 > Tier 2 > Tier 3).\n",
        "\n",
        "**Occupation:** Customer's occupation (e.g., Salaried, Freelancer).\n",
        "\n",
        "**Gender:** Gender of the customer (Male, Female).\n",
        "\n",
        "**NumberOfPersonVisiting:** Total number of people accompanying the customer on the trip.\n",
        "\n",
        "**PreferredPropertyStar:** Preferred hotel rating by the customer.\n",
        "\n",
        "**MaritalStatus:** Marital status of the customer (Single, Married, Divorced).\n",
        "\n",
        "**NumberOfTrips:** Average number of trips the customer takes annually.\n",
        "\n",
        "**Passport:** Whether the customer holds a valid passport (0: No, 1: Yes).\n",
        "\n",
        "**OwnCar:** Whether the customer owns a car (0: No, 1: Yes).\n",
        "\n",
        "**NumberOfChildrenVisiting:** Number of children below age 5 accompanying the customer.\n",
        "\n",
        "**Designation:** Customer's designation in their current organization.\n",
        "\n",
        "**MonthlyIncome:** Gross monthly income of the customer.\n",
        "\n",
        "**Customer Interaction Data**\n",
        "\n",
        "**PitchSatisfactionScore:** Score indicating the customer's satisfaction with the sales pitch.\n",
        "\n",
        "**ProductPitched:** The type of product pitched to the customer.\n",
        "\n",
        "**NumberOfFollowups:** Total number of follow-ups by the salesperson after the sales pitch.\n",
        "\n",
        "**DurationOfPitch:** Duration of the sales pitch delivered to the customer."
      ],
      "metadata": {
        "id": "8t5SLARtL7ol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prerequisites**\n",
        "\n",
        "- Create a Github repo\n",
        "  - Go to **Github Profile**\n",
        "  - Click on **Your repositories** then select ***New***\n",
        "    - Repository Name: **TourPkg_Prediction**\n",
        "    - Check the box **README.md** file\n",
        "    - Click on **Create repository**\n",
        "- Adding hugging face space secrets to Github Actions to execute the workflow\n",
        "  - Go to Hugging Face **Profile**\n",
        "  - Navigate to **Access Token**\n",
        "  - Create a **New token**\n",
        "    - Token type **Write**\n",
        "    - Token Name **MLOps**\n",
        "    - Click on **Create Token**\n",
        "    - Copy the generated Token\n",
        "  - Now, go to Github repo\n",
        "    - Click on **Settings**\n",
        "    - Navigate to **Secrets and Variables**\n",
        "    - Click on **Actions**\n",
        "    - Add a **Repository secerts**\n",
        "      - Name **HF_TOKEN**\n",
        "      - Secret: **Paste the token created from the hugging face access tokens**\n",
        "      - Click on **Add secret**\n",
        "      \n",
        "- Create a Hugging Face space\n",
        "  - Go to **Hugging Face**\n",
        "  - Open your **Profile**\n",
        "  - Click on **New Space**\n",
        "      - Under the space creation, enter the below details\n",
        "        - Space name: **TourPkg-Prediction**\n",
        "          - Select the space **SDK: Docker** - Choose a Docker template: **Streamlit** - Click on **Create Space**"
      ],
      "metadata": {
        "id": "XwLPfkr1SoVo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Building**"
      ],
      "metadata": {
        "id": "qsNzDF-2gwZL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nDqlrL1pLB6W"
      },
      "outputs": [],
      "source": [
        "# Create a master folder to keep all files created when executing the below code cells\n",
        "import os\n",
        "os.makedirs(\"tourism_project\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a folder for storing the model building files\n",
        "os.makedirs(\"tourism_project/model_building\", exist_ok=True)"
      ],
      "metadata": {
        "id": "N54-2kKcgsT1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Registration**\n",
        "\n",
        "Create a master folder and create a subfolder \"data\" - Register the data on the Hugging Face dataset space\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ul4KCdgihCqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"tourism_project/data\", exist_ok=True)"
      ],
      "metadata": {
        "id": "gcOnUrddg8mM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the data folder created after executing the above cell, upload the tourism.csv in to the folder"
      ],
      "metadata": {
        "id": "HIVpKBfXhmRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tourism_project/model_building/data_register.py\n",
        "from huggingface_hub.utils import RepositoryNotFoundError, HfHubHTTPError\n",
        "from huggingface_hub import HfApi, create_repo\n",
        "import os\n",
        "\n",
        "\n",
        "repo_id = \"<Sudu2025>/TourPkg_Prediction\"\n",
        "repo_type = \"dataset\"\n",
        "\n",
        "# Initialize API client\n",
        "api = HfApi(token=os.getenv(\"HF_TOKEN\"))\n",
        "\n",
        "# Step 1: Check if the space exists\n",
        "try:\n",
        "    api.repo_info(repo_id=repo_id, repo_type=repo_type)\n",
        "    print(f\"Space '{repo_id}' already exists. Using it.\")\n",
        "except RepositoryNotFoundError:\n",
        "    print(f\"Space '{repo_id}' not found. Creating new space...\")\n",
        "    create_repo(repo_id=repo_id, repo_type=repo_type, private=False)\n",
        "    print(f\"Space '{repo_id}' created.\")\n",
        "\n",
        "api.upload_folder(\n",
        "    folder_path=\"tourism_project/data\",\n",
        "    repo_id=repo_id,\n",
        "    repo_type=repo_type,\n",
        ")"
      ],
      "metadata": {
        "id": "Hg35tfQlhrXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f620ae69-e49f-4bb2-904c-909b139b479a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tourism_project/model_building/data_register.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preparation**\n",
        "- Load the dataset directly from the Hugging Face data space.\n",
        "- Perform data cleaning and remove any unnecessary columns.\n",
        "- Split the cleaned dataset into training and testing sets, and save them locally.\n",
        "- Upload the resulting train and test datasets back to the Hugging Face data space"
      ],
      "metadata": {
        "id": "r1fPHU8wHLgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tourism_project/model_building/prep.py\n",
        "# for data manipulation\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "# for creating a folder\n",
        "import os\n",
        "# for data preprocessing and pipeline creation\n",
        "from sklearn.model_selection import train_test_split\n",
        "# for converting text data in to numerical representation\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# for hugging face space authentication to upload files\n",
        "from huggingface_hub import login, HfApi\n",
        "\n",
        "# Define constants for the dataset and output paths\n",
        "api = HfApi(token=os.getenv(\"HF_TOKEN\"))\n",
        "DATASET_PATH = \"hf://datasets/<Sudu2025>/TourPkg_Prediction/tourism.csv\"\n",
        "df = pd.read_csv(DATASET_PATH)\n",
        "print(\"Dataset loaded successfully.\")\n",
        "\n",
        "# Drop unique identifier column (not useful for modeling)\n",
        "df.drop(columns=['CustomerID', 'OwnCar', 'NumberOfChildrenVisiting'], inplace=True)\n",
        "\n",
        "# Encode categorical columns\n",
        "label_encoder = LabelEncoder()\n",
        "df['TypeofContact'] = label_encoder.fit_transform(df['TypeofContact'])\n",
        "df['Occupation'] = label_encoder.fit_transform(df['Occupation'])\n",
        "df['Gender'] = label_encoder.fit_transform(df['Gender'])\n",
        "df['MaritalStatus'] = label_encoder.fit_transform(df['MaritalStatus'])\n",
        "df['ProductPitched'] = label_encoder.fit_transform(df['ProductPitched'])\n",
        "\n",
        "\n",
        "# Define target variable\n",
        "target_col = 'ProdTaken'\n",
        "\n",
        "# Split into X (features) and y (target)\n",
        "X = df.drop(columns=[target_col])\n",
        "y = df[target_col]\n",
        "\n",
        "# Perform train-test split\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "Xtrain.to_csv(\"Xtrain.csv\",index=False)\n",
        "Xtest.to_csv(\"Xtest.csv\",index=False)\n",
        "ytrain.to_csv(\"ytrain.csv\",index=False)\n",
        "ytest.to_csv(\"ytest.csv\",index=False)\n",
        "\n",
        "\n",
        "files = [\"Xtrain.csv\",\"Xtest.csv\",\"ytrain.csv\",\"ytest.csv\"]\n",
        "\n",
        "for file_path in files:\n",
        "    api.upload_file(\n",
        "        path_or_fileobj=file_path,\n",
        "        path_in_repo=file_path.split(\"/\")[-1],  # just the filename\n",
        "        repo_id=\"<Sudu2025>/TourPkg_Prediction\",\n",
        "        repo_type=\"dataset\",\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_xIj6lHHmMH",
        "outputId": "3fe45c48-44ff-487f-d193-c7054af541cd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tourism_project/model_building/prep.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Building with Experimentation Tracking-**\n",
        "- Load the train and test data from the Hugging Face data space\n",
        "- Define a model and parameters\n",
        "- Tune the model with the defined parameters\n",
        "- Log all the tuned parameters\n",
        "- Evaluate the model performance\n",
        "- Register the best model in the Hugging Face model hub\n",
        "* The ML models to be built can be any of the following algorithms, such as Decision Tree, Bagging, Random Forest, AdaBoost, Gradient Boosting, and XGBoost"
      ],
      "metadata": {
        "id": "4quPztjLP-9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tourism_project/model_building/train.py\n",
        "# for data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# for model training, tuning, and evaluation\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# for model serialization\n",
        "import joblib\n",
        "import os\n",
        "# for hugging face space authentication to upload files\n",
        "from huggingface_hub import login, HfApi, create_repo\n",
        "from huggingface_hub.utils import RepositoryNotFoundError, HfHubHTTPError\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "Xtrain_path = \"hf://datasets/<Sudu2025>/TourPkg_Prediction/Xtrain.csv\"\n",
        "Xtest_path = \"hf://datasets/<Sudu2025>/TourPkg_Prediction/Xtest.csv\"\n",
        "ytrain_path = \"hf://datasets/<Sudu2025>/TourPkg_Prediction/ytrain.csv\"\n",
        "ytest_path = \"hf://datasets/<Sudu2025>/TourPkg_Prediction/ytest.csv\"\n",
        "\n",
        "Xtrain = pd.read_csv(Xtrain_path)\n",
        "Xtest = pd.read_csv(Xtest_path)\n",
        "ytrain = pd.read_csv(ytrain_path)\n",
        "ytest = pd.read_csv(ytest_path)\n",
        "\n",
        "# Define features\n",
        "numeric_features = ['ProdTaken', 'Age', 'CityTier', 'NumberOfPersonVisiting', 'PreferredPropertyStar', 'NumberOfTrips','Passport','MonthlyIncome','PitchSatisfactionScore','NumberOfFollowups','DurationOfPitch']\n",
        "categorical_features = ['TypeofContact', 'Occupation', 'Gender', 'MaritalStatus', 'Designation', 'ProductPitched']\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = make_column_transformer(\n",
        "    (StandardScaler(), numeric_features),\n",
        "    (OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        ")\n",
        "\n",
        "# Define XGBoost Regressor\n",
        "xgb_model = xgb.XGBRegressor(random_state=42, objective=\"reg:squarederror\")\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'xgbregressor__n_estimators': [50, 100],\n",
        "    'xgbregressor__max_depth': [2, 3],\n",
        "    'xgbregressor__learning_rate': [0.01, 0.05],\n",
        "    'xgbregressor__colsample_bytree': [0.6, 0.8],\n",
        "    'xgbregressor__subsample': [0.6, 0.8],\n",
        "    'xgbregressor__reg_lambda': [0.5, 1],\n",
        "}\n",
        "\n",
        "# Create pipeline\n",
        "model_pipeline = make_pipeline(preprocessor, xgb_model)\n",
        "\n",
        "# Grid search with cross-validation\n",
        "grid_search = GridSearchCV(\n",
        "    model_pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1\n",
        ")\n",
        "grid_search.fit(Xtrain, ytrain)\n",
        "\n",
        "# Best model\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Best Params:\\n\", grid_search.best_params_)\n",
        "\n",
        "# Predictions\n",
        "y_pred_train = best_model.predict(Xtrain)\n",
        "y_pred_test = best_model.predict(Xtest)\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\nTraining Performance:\")\n",
        "print(\"MAE:\", mean_absolute_error(ytrain, y_pred_train))\n",
        "print(\"RMSE:\", np.sqrt(mean_squared_error(ytrain, y_pred_train)))\n",
        "print(\"R²:\", r2_score(ytrain, y_pred_train))\n",
        "\n",
        "print(\"\\nTest Performance:\")\n",
        "print(\"MAE:\", mean_absolute_error(ytest, y_pred_test))\n",
        "print(\"RMSE:\", np.sqrt(mean_squared_error(ytest, y_pred_test)))\n",
        "print(\"R²:\", r2_score(ytest, y_pred_test))\n",
        "\n",
        "# Save best model\n",
        "joblib.dump(best_model, \"tourismpkg_prediction_model_v1.joblib\")\n",
        "\n",
        "\n",
        "# Upload to Hugging Face\n",
        "repo_id = \"<Sudu2025>/TourPkg_Prediction/tourismpkg_prediction_model\"\n",
        "repo_type = \"model\"\n",
        "\n",
        "api = HfApi(token=os.getenv(\"HF_TOKEN\"))\n",
        "\n",
        "# Step 1: Check if the space exists\n",
        "try:\n",
        "    api.repo_info(repo_id=repo_id, repo_type=repo_type)\n",
        "    print(f\"Model Space '{repo_id}' already exists. Using it.\")\n",
        "except RepositoryNotFoundError:\n",
        "    print(f\"Model Space '{repo_id}' not found. Creating new space...\")\n",
        "    create_repo(repo_id=repo_id, repo_type=repo_type, private=False)\n",
        "    print(f\"Model Space '{repo_id}' created.\")\n",
        "\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"tourismpkg_prediction_model_v1.joblib\",\n",
        "    path_in_repo=\"tourismpkg_prediction_model_v1.joblib\",\n",
        "    repo_id=repo_id,\n",
        "    repo_type=repo_type,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2GhVm7ek1Dt",
        "outputId": "d41ad722-c079-4c8b-ea94-d85c39cdc0a1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tourism_project/model_building/train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Deployment**\n",
        "- Define a Dockerfile and list all configurations\n",
        "- Load the saved model from the Hugging Face model hub\n",
        "- Get the inputs and save them into a dataframe\n",
        "- Define a dependencies file for the deployment\n",
        "- Define a hosting script that can push all the deployment files into the Hugging Face space"
      ],
      "metadata": {
        "id": "ocmH47LcCp0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"tourism_project/deployment\", exist_ok=True)"
      ],
      "metadata": {
        "id": "eop0cLRLDC3d"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tourism_project/deployment/Dockerfile\n",
        "# Use a minimal base image with Python 3.9 installed\n",
        "FROM python:3.9\n",
        "\n",
        "# Set the working directory inside the container to /app\n",
        "WORKDIR /app\n",
        "\n",
        "# Copy all files from the current directory on the host to the container's /app directory\n",
        "COPY . .\n",
        "\n",
        "# Install Python dependencies listed in requirements.txt\n",
        "RUN pip3 install -r requirements.txt\n",
        "\n",
        "RUN useradd -m -u 1000 user\n",
        "USER user\n",
        "ENV HOME=/home/user \\\n",
        "\tPATH=/home/user/.local/bin:$PATH\n",
        "\n",
        "WORKDIR $HOME/app\n",
        "\n",
        "COPY --chown=user . $HOME/app\n",
        "\n",
        "# Define the command to run the Streamlit app on port \"8501\" and make it accessible externally\n",
        "CMD [\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.address=0.0.0.0\", \"--server.enableXsrfProtection=false\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J7ws40SDQOj",
        "outputId": "c4eed643-4d1c-481c-e8df-bcf67ec452f4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tourism_project/deployment/Dockerfile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Streamlit App**\n",
        "\n",
        "Please ensure that the web app script is named app.py."
      ],
      "metadata": {
        "id": "Agvuxs8TD-Kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tourism_project/deployment/app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from huggingface_hub import hf_hub_download\n",
        "import joblib\n",
        "\n",
        "# Download and load the model from Hugging Face Hub\n",
        "model_path = hf_hub_download(\n",
        "    repo_id=\"<Sudu2025>/TourPkg_Prediction/tourismpkg_prediction_model\",\n",
        "    filename=\"tourismpkg_prediction_model_v1.joblib\"\n",
        ")\n",
        "model = joblib.load(model_path)\n",
        "\n",
        "# Streamlit UI for Insurance Charges Prediction\n",
        "st.title(\"Tourism Package Prediction App\")\n",
        "st.write(\"\"\"\n",
        "This application predicts the **Best Tourism Package** based on personal and lifestyle details.\n",
        "Please enter the required information below to get a prediction.\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "CustomerID: Unique identifier for each customer.\n",
        "\n",
        "ProdTaken: Target variable indicating whether the customer has purchased a package (0: No, 1: Yes).\n",
        "\n",
        "Age: Age of the customer.\n",
        "\n",
        "TypeofContact: The method by which the customer was contacted (Company Invited or Self Inquiry).\n",
        "\n",
        "CityTier: The city category based on development, population, and living standards (Tier 1 > Tier 2 > Tier 3).\n",
        "\n",
        "Occupation: Customer's occupation (e.g., Salaried, Freelancer).\n",
        "\n",
        "Gender: Gender of the customer (Male, Female).\n",
        "\n",
        "NumberOfPersonVisiting: Total number of people accompanying the customer on the trip.\n",
        "\n",
        "PreferredPropertyStar: Preferred hotel rating by the customer.\n",
        "\n",
        "MaritalStatus: Marital status of the customer (Single, Married, Divorced).\n",
        "\n",
        "NumberOfTrips: Average number of trips the customer takes annually.\n",
        "\n",
        "Passport: Whether the customer holds a valid passport (0: No, 1: Yes).\n",
        "\n",
        "OwnCar: Whether the customer owns a car (0: No, 1: Yes).\n",
        "\n",
        "NumberOfChildrenVisiting: Number of children below age 5 accompanying the customer.\n",
        "\n",
        "Designation: Customer's designation in their current organization.\n",
        "\n",
        "MonthlyIncome: Gross monthly income of the customer.\n",
        "\n",
        "Customer Interaction Data\n",
        "\n",
        "PitchSatisfactionScore: Score indicating the customer's satisfaction with the sales pitch.\n",
        "\n",
        "ProductPitched: The type of product pitched to the customer.\n",
        "\n",
        "NumberOfFollowups: Total number of follow-ups by the salesperson after the sales pitch.\n",
        "\n",
        "DurationOfPitch: Duration of the sales pitch delivered to the customer.\n",
        "\n",
        "\n",
        "\n",
        "# User input\n",
        "age = st.number_input(\"Age\", min_value=18, max_value=100, value=30, step=1)\n",
        "typeofcontact = st.selectbox(\"TypeofContact\", [\"Company Invited\", \"Self Enquiry\"])\n",
        "citytier = st.number_input(\"CityTier\", min_value=1, max_value=3, value=1, step=1)\n",
        "occupation = st.selectbox(\"Occupation\", [\"Salaried\", \"Free Lancer\", \"Small Business\", \"Large Business\"])\n",
        "gender = st.selectbox(\"Gender\", [\"male\", \"female\"])\n",
        "nrofpersonvisiting = st.number_input(\"NumberOfPersonVisiting\", min_value=1, max_value=8, value=2, step=1)\n",
        "prfpropertystar = st.number_input(\"PreferredPropertyStar\", min_value=3, max_value=5, value=3, step=1)\n",
        "maritalstatus = st.selectbox(\"MaritalStatus\", [\"Single\", \"Married\", \"Unmarried\", \"Divorced\"])\n",
        "nroftrips = st.number_input(\"NumberOfTrips\", min_value=1, max_value=20, value=3, step=1)\n",
        "passport =  st.number_input(\"Passport\", min_value=0, max_value=1, value=1, step=1)\n",
        "designation = st.selectbox(\"Designation\", [\"Manager\", \"Senior Manager\", \"Executive\", \"AVP\", \"VP\"])\n",
        "monthlyincome = st.number_input(\"MonthlyIncome\", min_value=1000, max_value=40000, value=5000, step=100)\n",
        "csi = st.number_input(\"PitchSatisfactionScore\", min_value=1, max_value=5, value=2, step=1)\n",
        "productpitched = st.selectbox(\"ProductPitched\", [\"Basic\", \"Standard\", \"Deluxe\", \"Super Deluxe\", \"King\"])\n",
        "nroffups = st.number_input(\"NumberOfFollowups\", min_value=1, max_value=6, value=2, step=1)\n",
        "pitchduration = st.number_input(\"DurationOfPitch\", min_value=5, max_value=40, value=10, step=1)\n",
        "\n",
        "# Assemble input into DataFrame\n",
        "input_data = pd.DataFrame([{\n",
        "    'age': age,\n",
        "    'typeofcontact': typeofcontact\n",
        "    'sex': sex,\n",
        "    'bmi': bmi,\n",
        "    'children': children,\n",
        "    'smoker': smoker,\n",
        "    'region': region\n",
        "}])\n",
        "\n",
        "# Prediction\n",
        "if st.button(\"Predict Charges\"):\n",
        "    prediction = model.predict(input_data)[0]\n",
        "    st.subheader(\"Prediction Result:\")\n",
        "    st.success(f\"Estimated Insurance Charges: **${prediction:,.2f}**\")"
      ],
      "metadata": {
        "id": "vVnDorw5ECSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Snj1CRZcGTwO"
      }
    }
  ]
}