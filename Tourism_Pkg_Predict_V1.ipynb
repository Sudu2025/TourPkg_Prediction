{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSFlQlIKt69zwPnfIn6zs/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sudu2025/TourPkg_Prediction/blob/main/Tourism_Pkg_Predict_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement**\n",
        "\n",
        "**Business Context**\n",
        "\n",
        "\"Visit with Us,\" a leading travel company, is revolutionizing the tourism industry by leveraging data-driven strategies to optimize operations and customer engagement. While introducing a new package offering, such as the Wellness Tourism Package, the company faces challenges in targeting the right customers efficiently. The manual approach to identifying potential customers is inconsistent, time-consuming, and prone to errors, leading to missed opportunities and suboptimal campaign performance.\n",
        "\n",
        "To address these issues, the company aims to implement a scalable and automated system that integrates customer data, predicts potential buyers, and enhances decision-making for marketing strategies. By utilizing an MLOps pipeline, the company seeks to achieve seamless integration of data preprocessing, model development, deployment, and CI/CD practices for continuous improvement. This system will ensure efficient targeting of customers, timely updates to the predictive model, and adaptation to evolving customer behaviors, ultimately driving growth and customer satisfaction.\n",
        "\n",
        "**Objective**\n",
        "\n",
        "As an MLOps Engineer at \"Visit with Us,\" your responsibility is to **design and deploy an MLOps pipeline on GitHub to automate the end-to-end workflow for predicting customer purchases**. The primary objective is to build a model that predicts whether a customer will purchase the newly introduced Wellness Tourism Package before contacting them. The pipeline will include data cleaning, preprocessing, transformation, model building, training, evaluation, and deployment, ensuring consistent performance and scalability. By leveraging GitHub Actions for CI/CD integration, the system will enable automated updates, streamline model deployment, and improve operational efficiency. This robust predictive solution will empower policymakers to make data-driven decisions, enhance marketing strategies, and effectively target potential customers, thereby driving customer acquisition and business growth.\n",
        "\n",
        "**Data Description**\n",
        "\n",
        "The dataset contains customer and interaction data that serve as key attributes for predicting the likelihood of purchasing the Wellness Tourism Package. The detailed attributes are:\n",
        "\n",
        "\n",
        "**Customer Details**\n",
        "\n",
        "**CustomerID:** Unique identifier for each customer.\n",
        "\n",
        "**ProdTaken:** Target variable indicating whether the customer has purchased a package (0: No, 1: Yes).\n",
        "\n",
        "**Age:** Age of the customer.\n",
        "\n",
        "**TypeofContact:** The method by which the customer was contacted (Company Invited or Self Inquiry).\n",
        "\n",
        "**CityTier:** The city category based on development, population, and living standards (Tier 1 > Tier 2 > Tier 3).\n",
        "\n",
        "**Occupation:** Customer's occupation (e.g., Salaried, Freelancer).\n",
        "\n",
        "**Gender:** Gender of the customer (Male, Female).\n",
        "\n",
        "**NumberOfPersonVisiting:** Total number of people accompanying the customer on the trip.\n",
        "\n",
        "**PreferredPropertyStar:** Preferred hotel rating by the customer.\n",
        "\n",
        "**MaritalStatus:** Marital status of the customer (Single, Married, Divorced).\n",
        "\n",
        "**NumberOfTrips:** Average number of trips the customer takes annually.\n",
        "\n",
        "**Passport:** Whether the customer holds a valid passport (0: No, 1: Yes).\n",
        "\n",
        "**OwnCar:** Whether the customer owns a car (0: No, 1: Yes).\n",
        "\n",
        "**NumberOfChildrenVisiting:** Number of children below age 5 accompanying the customer.\n",
        "\n",
        "**Designation:** Customer's designation in their current organization.\n",
        "\n",
        "**MonthlyIncome:** Gross monthly income of the customer.\n",
        "\n",
        "**Customer Interaction Data**\n",
        "\n",
        "**PitchSatisfactionScore:** Score indicating the customer's satisfaction with the sales pitch.\n",
        "\n",
        "**ProductPitched:** The type of product pitched to the customer.\n",
        "\n",
        "**NumberOfFollowups:** Total number of follow-ups by the salesperson after the sales pitch.\n",
        "\n",
        "**DurationOfPitch:** Duration of the sales pitch delivered to the customer."
      ],
      "metadata": {
        "id": "8t5SLARtL7ol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Building**"
      ],
      "metadata": {
        "id": "qsNzDF-2gwZL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nDqlrL1pLB6W"
      },
      "outputs": [],
      "source": [
        "# Create a master folder to keep all files created when executing the below code cells\n",
        "import os\n",
        "os.makedirs(\"tourism_project\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a folder for storing the model building files\n",
        "os.makedirs(\"tourism_project/model_building\", exist_ok=True)"
      ],
      "metadata": {
        "id": "N54-2kKcgsT1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Registration**\n",
        "\n",
        "Create a master folder and create a subfolder \"data\" - Register the data on the Hugging Face dataset space\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ul4KCdgihCqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"tourism_project/data\", exist_ok=True)"
      ],
      "metadata": {
        "id": "gcOnUrddg8mM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the data folder created after executing the above cell, upload the tourism.csv in to the folder"
      ],
      "metadata": {
        "id": "HIVpKBfXhmRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tourism_project/model_building/data_register.py\n",
        "from huggingface_hub.utils import RepositoryNotFoundError, HfHubHTTPError\n",
        "from huggingface_hub import HfApi, create_repo\n",
        "import os\n",
        "\n",
        "\n",
        "repo_id = \"<Sudu2025>/TourPkg_Prediction\"\n",
        "repo_type = \"dataset\"\n",
        "\n",
        "# Initialize API client\n",
        "api = HfApi(token=os.getenv(\"HF_TOKEN\"))\n",
        "\n",
        "# Step 1: Check if the space exists\n",
        "try:\n",
        "    api.repo_info(repo_id=repo_id, repo_type=repo_type)\n",
        "    print(f\"Space '{repo_id}' already exists. Using it.\")\n",
        "except RepositoryNotFoundError:\n",
        "    print(f\"Space '{repo_id}' not found. Creating new space...\")\n",
        "    create_repo(repo_id=repo_id, repo_type=repo_type, private=False)\n",
        "    print(f\"Space '{repo_id}' created.\")\n",
        "\n",
        "api.upload_folder(\n",
        "    folder_path=\"tourism_project/data\",\n",
        "    repo_id=repo_id,\n",
        "    repo_type=repo_type,\n",
        ")"
      ],
      "metadata": {
        "id": "Hg35tfQlhrXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa2f5ddc-f761-46d4-af87-0ec03ac40022"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tourism_project/model_building/data_register.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preparation**\n",
        "- Load the dataset directly from the Hugging Face data space.\n",
        "- Perform data cleaning and remove any unnecessary columns.\n",
        "- Split the cleaned dataset into training and testing sets, and save them locally.\n",
        "- Upload the resulting train and test datasets back to the Hugging Face data space"
      ],
      "metadata": {
        "id": "r1fPHU8wHLgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tourism_project/model_building/prep.py\n",
        "# for data manipulation\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "# for creating a folder\n",
        "import os\n",
        "# for data preprocessing and pipeline creation\n",
        "from sklearn.model_selection import train_test_split\n",
        "# for converting text data in to numerical representation\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# for hugging face space authentication to upload files\n",
        "from huggingface_hub import login, HfApi\n",
        "\n",
        "# Define constants for the dataset and output paths\n",
        "api = HfApi(token=os.getenv(\"HF_TOKEN\"))\n",
        "DATASET_PATH = \"hf://datasets/<Sudu2025>/TourPkg_Prediction/tourism.csv\"\n",
        "df = pd.read_csv(DATASET_PATH)\n",
        "print(\"Dataset loaded successfully.\")\n",
        "\n",
        "# Drop unique identifier column (not useful for modeling)\n",
        "df.drop(columns=['CustomerID', 'OwnCar', 'NumberOfChildrenVisiting'], inplace=True)\n",
        "\n",
        "# Encode categorical columns\n",
        "label_encoder = LabelEncoder()\n",
        "df['TypeofContact'] = label_encoder.fit_transform(df['TypeofContact'])\n",
        "df['Occupation'] = label_encoder.fit_transform(df['Occupation'])\n",
        "df['Gender'] = label_encoder.fit_transform(df['Gender'])\n",
        "df['MaritalStatus'] = label_encoder.fit_transform(df['MaritalStatus'])\n",
        "df['ProductPitched'] = label_encoder.fit_transform(df['ProductPitched'])\n",
        "\n",
        "\n",
        "# Define target variable\n",
        "target_col = 'ProdTaken'\n",
        "\n",
        "# Split into X (features) and y (target)\n",
        "X = df.drop(columns=[target_col])\n",
        "y = df[target_col]\n",
        "\n",
        "# Perform train-test split\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "Xtrain.to_csv(\"Xtrain.csv\",index=False)\n",
        "Xtest.to_csv(\"Xtest.csv\",index=False)\n",
        "ytrain.to_csv(\"ytrain.csv\",index=False)\n",
        "ytest.to_csv(\"ytest.csv\",index=False)\n",
        "\n",
        "\n",
        "files = [\"Xtrain.csv\",\"Xtest.csv\",\"ytrain.csv\",\"ytest.csv\"]\n",
        "\n",
        "for file_path in files:\n",
        "    api.upload_file(\n",
        "        path_or_fileobj=file_path,\n",
        "        path_in_repo=file_path.split(\"/\")[-1],  # just the filename\n",
        "        repo_id=\"<Sudu2025>/TourPkg_Prediction\",\n",
        "        repo_type=\"dataset\",\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_xIj6lHHmMH",
        "outputId": "d3aec2d9-0ad9-41ab-b417-aacc041c7ada"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tourism_project/model_building/prep.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Building with Experimentation Tracking-**\n",
        "- Load the train and test data from the Hugging Face data space\n",
        "- Define a model and parameters\n",
        "- Tune the model with the defined parameters\n",
        "- Log all the tuned parameters\n",
        "- Evaluate the model performance\n",
        "- Register the best model in the Hugging Face model hub\n",
        "* The ML models to be built can be any of the following algorithms, such as Decision Tree, Bagging, Random Forest, AdaBoost, Gradient Boosting, and XGBoost"
      ],
      "metadata": {
        "id": "4quPztjLP-9z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6iOGPzqQQVrS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}